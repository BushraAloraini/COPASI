<chapter id="methods" xreflabel="Methods">
<title>Methods</title>

<sect1 id="methodTimeCourse" xreflabel="Time Course">
<title>Time Course Calculation</title>

<para>
With the time course simulation, you can calculate the trajectory for
the species in your model over a given time interval. There are
different methods to calculate such trajectories and depending on your
model, one or several of them may be appropriate to do a time course
simulation of your model.
</para>

<para>
COPASI supports three different methodologies to calculate a
trajectory. The first method is to do a deterministic time course
simulation of your model using the LSODA
<citation>Petzold83</citation> algorithm. For systems with  
small particle numbers, it is sometimes better to do a stochastic
simulation rather than a deterministic one. COPASI supports a method
for the stochastic calculation of time series, which is called
<guilabel>stochastic</guilabel> and uses the next reaction method
described by Gibson and Bruck.
<!--
The other method for stochastic simulation is the
Tau-Leap method described in ???.
-->
</para>

<para>Since the deterministic simulation is inappropriate for some
systems but on the other hand, the stochastic simulation is too time
consuming, there are some methods that try to combine the advantages
of both deterministic and stochastic simulation. Most of those methods
are termed hybrid methods. COPASI also includes such a hybrid method
which in some systems where deterministic simulation would lead to
incorrect results will give the correct time series but is still
computationally less demanding than a pure stochastic simulation.
</para>

<sect2 id="DeterministicSimulation" xreflabel="DeterministicSimulation">
<title>Deterministic Simulation</title>

<sect3 id="LSODA" xreflabel="LSODA">
<title>Deterministic (LSODA)</title>
<para>
The default method in COPASI to calculate a time course is
LSODA <citation>Petzold83</citation>. LSODA is part of the <ulink
url="http://www.netlib.org/odepack/opkd-sum">
ODEPACK</ulink> library <citation>Hindmarsh83</citation>.
LSODA was written by Linda R. Petzold and Alan C. Hindmarsh.
<!--
	Computing and Mathematics Research Division,
	Lawrence Livermore National Laboratory,
	Livermore, CA 94550, U.S.A.
-->
It solves systems <mml:math><mml:mi>dy</mml:mi><mml:mo>/</mml:mo>
<mml:mi>dt</mml:mi><mml:mo> = </mml:mo><mml:mi>f </mml:mi></mml:math> 
with a dense or banded Jacobian when the problem is stiff, but it
automatically selects between non-stiff (Adams) and stiff (BDF)
methods.  It uses the non-stiff method initially, and dynamically
monitors data in order to decide which method to use.
</para>

<variablelist><title>Options for LSODA</title>
<varlistentry><term>Integrate Reduced Model</term>
<listitem>
<para>
This parameter is a boolean value to determine whether the integration
shall be performed using the mass conservation laws, i.e., reducing
the number of system variables or to use the complete model. A value of
'1' (the default) instructs COPASI to make use of the mass
conservation laws, whereas a value of '0' instructs COPASI to
determine all variables through ODEs. 
</para>
</listitem>
</varlistentry>
<varlistentry><term>Relative Tolerance</term>
<listitem>
<para>
This parameter is a numeric value specifying the desired relative
tolerance the user wants to achieve. A smaller value means that the
trajectory is calculated more accurate. The default value is
<mml:math><mml:mn>1.0</mml:mn><mml:mo>*</mml:mo>
<mml:msup><mml:mn>10</mml:mn><mml:mn>-6</mml:mn></mml:msup></mml:math>.
Please note that best achievable relative tolerance is approximately 
<mml:math><mml:mn>2.22</mml:mn><mml:mo>*</mml:mo>
<mml:msup><mml:mn>10</mml:mn><mml:mn>-16</mml:mn></mml:msup></mml:math>.
</para>
</listitem>
</varlistentry>
<varlistentry><term>Use Default Absolute Tolerance</term>
<listitem>
<para>
This parameter is a boolean value to determine whether COPASI shall
make a guess for the absolute tolerance. The absolute tolerance
determines whether numbers are considered to be zero during
calculation. Numbers with an absolute values less than the absolute
tolerance are treated as zero. A value of '1' (the default) instructs
COPASI to make a guess which can be found in the Absolute Tolerance
parameter after calculation. When specifying a value of '0' one needs
also to provide a value for the absolute tolerance.
</para>
</listitem>
</varlistentry>
<varlistentry><term>Absolute Tolerance</term>
<listitem>
<para>
This parameter is a numeric value specifying the desired absolute
tolerance the user wants to achieve or if Use Default Absolute
Tolerance parameter is set '1' the value COPASI selected. Please note
that COPASI internally calculates with particle numbers which might be
quite large (<mml:math><mml:mn>1.0</mml:mn><mml:mo>*</mml:mo>
<mml:msup><mml:mn>10</mml:mn><mml:mn>23</mml:mn></mml:msup></mml:math>)
and therefore an absolute tolerance of 
<mml:math><mml:mn>1.0</mml:mn><mml:mo>*</mml:mo>
<mml:msup><mml:mn>10</mml:mn><mml:mn>9</mml:mn></mml:msup></mml:math>
is already small.
</para>
</listitem>
</varlistentry>
<varlistentry><term>Adams Max Order</term>
<listitem>
<para>
This parameter is a positive integer value specifying the maximal
order the non-stiff Adams integration method shall attempt before
switching to the stiff BDF method. The default and maximal order is '12'.
</para>
</listitem>
</varlistentry>
<varlistentry><term>BDF Max Order</term>
<listitem>
<para>
This parameter is a positive integer value specifying the maximal
order the stiff BDF integration method shall attempt before switching
to smaller internal step sizes. The default and maximal order is '5'.
</para>
</listitem>
</varlistentry>
<varlistentry><term>Max Internal Steps</term>
<listitem>
<para>
This parameter is a positive integer value specifying the maximal
number of internal steps the integrator is allowed to take before the
next desired reporting time. The default value is '10000'. 
</para>
</listitem>
</varlistentry>
</variablelist>

</sect3>
</sect2>
<sect2 id="StochasticSimulation" xreflabel="Stochastic Simulation">
<title>Stochastic Simulation</title>
<sect3 id="NextReactionMethod" xreflabel="Next Reaction Method">
<title>The Next-Reaction-Method</title>
<para>
To be written.
</para>

<variablelist><title>Options for Stochastic (Gibson + Bruck)</title>
<varlistentry><term>Max Internal Steps</term>
<listitem>
<para>
To be written
</para>
</listitem>
</varlistentry>
<varlistentry><term>Subtype</term>
<listitem>
<para>
To be written
</para>
</listitem>
</varlistentry>
<varlistentry><term>Use Random Seed</term>
<listitem>
<para>
To be written
</para>
</listitem>
</varlistentry>
<varlistentry><term>Random Seed</term>
<listitem>
<para>
To be written
</para>
</listitem>
</varlistentry>
</variablelist>

<!--
</sect3>
<sect3 id="TauLeap" xreflabel="Tau Leap">
<title>Stochastic (Tau-Leap)</title>
<para>
To be written.
</para>

<variablelist><title>Options for the Tau-Leap Method</title>
<varlistentry><term>TAU</term>
<listitem>
<para>
To be written
</para>
</listitem>
</varlistentry>
<varlistentry><term>UseRandomSeed</term>
<listitem>
<para>
To be written
</para>
</listitem>
</varlistentry>
<varlistentry><term>RandomSeed</term>
<listitem>
<para>
To be written
</para>
</listitem>
</varlistentry>
</variablelist>
-->

</sect3>
</sect2>
<sect2 id="HybridSimulation" xreflabel="Hybrid Simulation">
<title>Hybrid Simulation</title>
<sect3 id="HybridRungeKutta" xreflabel="Hybrid Runge Kutta">
<title>Hybrid (Runge-Kutta)</title>
<para>
This hybrid simulation method developed by us combines a deterministic numerical integration of ODEs with a stochastic simulation algorithm. The whole biochemical network is partitioned into a deterministic and a stochastic subnet internally. The deterministic subnet contains all reactions, in which only metabolites with high particle numbers take part. All reactions with at least one low-numbered metabolite are in the stochastic subnet, because here stochastic effects are expected. Which particle numbers are considered low or high can be specified by the user with the Lower Limit and the Upper Limit parameters (Metabolites with particle numbers between those limits do not change their status. This leads to a hysteresis-like behavior and avoids many unnecessary swaps, if the particle numbers fluctuate in the middle range). The partitioning of the biochemical network can change dynamically during the simulation. After a certain number of steps, which the user can define using the parameter Partitioning Interval, the partitioning is recalculated using the current particle numbers in the system. During one run the deterministic subnet and the stochastic subnet are simulated in parallel. A 4th-order Runge-Kutta method is used to numerically integrate the deterministic part of the system. For the stochastic part the simulation method by Gibson and Bruck is utilized. The reaction probabilities of the stochastic subnet are approximated as constant during one stochastic step, even though in theory they can change due to the effects of the deterministic subnet.
</para>

<variablelist><title>Options for Hybrid (Runge-Kutta)</title>

<varlistentry><term>Max Internal Steps</term>
<listitem>
<para>
This parameter is a positive integer value specifying the maximal
number of internal steps the integrator is allowed to take before the
next desired reporting time. The default value is '1000000'. 
</para>
</listitem>
</varlistentry>

<varlistentry><term>Lower Limit</term>
<listitem>
<para>
This parameter is a double value specifying the lower limit for particle numbers. Metabolites with a particle number below this value are considered as having a low particle number. The lower limit cannot be higher than the upper limit. The default value is '800'.
</para>
</listitem>
</varlistentry>

<varlistentry><term>Upper Limit</term>
<listitem>
<para>
This parameter is a double value specifying the upper limit for particle numbers. Metabolites with a particle number above this value are considered as having a high particle number. The upper limit cannot be lower than the lower limit. The default value is '1000'.
</para>
</listitem>
</varlistentry>

<varlistentry><term>Runge Kutta Stepsize</term>
<listitem>
<para>
This positive double value is the step size of the Runge-Kutta solver for the integration of the deterministic part of the system. The default value is '0.001'.
</para>
</listitem>
</varlistentry>

<varlistentry><term>Partitioning Interval</term>
<listitem>
<para>
This positive integer value specifies after how many steps the internal partitioning of the system should be recalculated. The default is '1', i.e. after every step the partitioning of the system is checked.
</para>
</listitem>
</varlistentry>

<varlistentry><term>Use Random Seed</term>
<listitem>
<para>
This flag can be '0' or '1' and determines if the user-defined random seed should be used for the calculation. The default is '0' meaning that the random seed is set to a random value before each run and consecutively calculated trajectories will be different. If the value of this flag is set to '1', the user-defined random seed will be used and each calculated trajectory will be the same for the same value of the given random seed.
</para>
</listitem>
</varlistentry>

<varlistentry><term>Random Seed</term>
<listitem>
<para>
This unsigned integer is used as random seed in the calculations, if the flag Use Random Seed is set to '1'. The default value is '1'.
</para>
</listitem>
</varlistentry>
</variablelist>

</sect3>
</sect2>
</sect1>
<sect1 id="methodSteadyState" xreflabel="Steady State">
<title>Steady State Calculation</title>
<para>
The steady state is the state in which the state variables of the
model, e.g. the metabolite concentrations do not change in
time. Mathematically this is expressed 
by setting the differential equations that describe the time evolution
of the metabolic system to zero. This forms a system of algebraic
non-linear equations. To solve them, COPASI can use a series of
strategies using more than one numerical method.
</para> 
<para>
  All calculations are done based on particle numbers and particle number rates rather than concentrations internally. The reduced model (see <xref linkend="deterministicModel" />) is used. The Jacobian (which is used in the Newton method and when eigenvalues of the Jacobian are requested) is calculated using finite differences. The eigenvalues of the Jacobian are calculated using CLAPACK.
</para>
<variablelist><title>Options for Steady State Analysis</title>
<varlistentry><term>Use Newton</term>
<listitem>
<para>
This parameter is a boolean value to determine whether to use the
damped Newton method on the non-linear algebraic equations 
defining the steady-state. The initial concentrations set by the user
are taken as guesses for the solution. A value of '1' (the default)
indicates that COPASI shall use the damped Newton method.
</para>
<para>
The damped Newton method is a variant of the famous Newton method for
the solution of systems of non-linear equations. The solution is
obtained from an iterative procedure that refines an initial guess
until the residual error is smaller than required. If a limit number
of iterations is reached without an acceptable solution, the method
halts without a solution.
</para>
<para>
The iteration of the plain Newton  method is:
</para>
<para>
<mml:math>
 <mml:mrow>
  <mml:msub>
   <mml:mi>x</mml:mi>
   <mml:mi>i</mml:mi>
  </mml:msub>
  <mml:mo>=</mml:mo>
  <mml:mrow>
   <mml:msub>
    <mml:mi>x</mml:mi>
    <mml:mrow>
     <mml:mi>i</mml:mi>
     <mml:mo>-</mml:mo>
     <mml:mn>1</mml:mn>
    </mml:mrow>
   </mml:msub>
   <mml:mo>-</mml:mo>
   <mml:mfrac>
    <mml:mrow>
     <mml:mi>f</mml:mi>
     <mml:mrow>
      <mml:mo>(</mml:mo>
      <mml:msub>
       <mml:mi>x</mml:mi>
       <mml:mrow>
        <mml:mi>i</mml:mi>
        <mml:mo>-</mml:mo>
        <mml:mn>1</mml:mn>
       </mml:mrow>
      </mml:msub>
      <mml:mo>)</mml:mo>
     </mml:mrow>
    </mml:mrow>
    <mml:mrow>
     <mml:mi>f</mml:mi>
     <mml:mi>&apos;</mml:mi>
     <mml:mrow>
      <mml:mo>(</mml:mo>
      <mml:msub>
       <mml:mi>x</mml:mi>
       <mml:mrow>
        <mml:mi>i</mml:mi>
        <mml:mo>-</mml:mo>
        <mml:mn>1</mml:mn>
       </mml:mrow>
      </mml:msub>
      <mml:mo>)</mml:mo>
     </mml:mrow>
    </mml:mrow>
   </mml:mfrac>
  </mml:mrow>
 </mml:mrow>
</mml:math>
</para>
<para>
In the damped method if 
<mml:math>
 <mml:msub>
  <mml:mi>x</mml:mi>
  <mml:mrow>
   <mml:mi>i</mml:mi>
   <mml:mo>-</mml:mo>
   <mml:mn>1</mml:mn>
  </mml:mrow>
 </mml:msub>
</mml:math> 
has a larger residual error than
<mml:math>
 <mml:msub>
  <mml:mi>x</mml:mi>
  <mml:mi>i</mml:mi>
 </mml:msub>
</mml:math> one looks at
</para>
<para>
<mml:math>
 <mml:mrow>
  <mml:msub>
   <mml:mi>x</mml:mi>
   <mml:mi>i</mml:mi>
  </mml:msub>
  <mml:mo>=</mml:mo>
  <mml:mrow>
   <mml:msub>
    <mml:mi>x</mml:mi>
    <mml:mrow>
     <mml:mi>i</mml:mi>
     <mml:mo>-</mml:mo>
     <mml:mn>1</mml:mn>
    </mml:mrow>
   </mml:msub>
   <mml:mo>-</mml:mo>
   <mml:mfrac>
    <mml:mrow>
     <mml:mi>f</mml:mi>
     <mml:mrow>
      <mml:mo>(</mml:mo>
      <mml:msub>
       <mml:mi>x</mml:mi>
       <mml:mrow>
        <mml:mi>i</mml:mi>
        <mml:mo>-</mml:mo>
        <mml:mn>1</mml:mn>
       </mml:mrow>
      </mml:msub>
      <mml:mo>)</mml:mo>
     </mml:mrow>
    </mml:mrow>
    <mml:mrow>
     <mml:mi>f</mml:mi>
     <mml:mi>&apos;</mml:mi>
     <mml:mrow>
      <mml:mo>(</mml:mo>
      <mml:msub>
       <mml:mi>x</mml:mi>
       <mml:mrow>
        <mml:mi>i</mml:mi>
        <mml:mo>-</mml:mo>
        <mml:mn>1</mml:mn>
       </mml:mrow>
      </mml:msub>
      <mml:mo>)</mml:mo>
     </mml:mrow>
    </mml:mrow>
   </mml:mfrac>
   <mml:mo>*</mml:mo>
   <mml:msup>
    <mml:mn>2</mml:mn>
    <mml:mrow>
     <mml:mo>-</mml:mo>
     <mml:mi>n</mml:mi>
    </mml:mrow>
   </mml:msup>
  </mml:mrow>
 </mml:mrow>
</mml:math> where
<mml:math>
 <mml:mi>n</mml:mi>
 <mml:mo>=</mml:mo>
 <mml:mn>0,</mml:mn>
 <mml:mn>...</mml:mn>
 <mml:mi>, </mml:mi>
 <mml:mn>32</mml:mn>
</mml:math>
</para>
<para>
and accepts the first such value that has a smaller residual
error than
<mml:math>
 <mml:msub>
  <mml:mi>x</mml:mi>
  <mml:mi>i</mml:mi>
 </mml:msub>
</mml:math>. If none is found, the procedure halts without a
solution (because it is at a local minimum). 
</para>
</listitem>
</varlistentry>
<varlistentry><term>Use Integration</term>
<listitem>
<para>
This parameter is a boolean value to determine whether to use the ODE
solver (<xref linkend="LSODA">LSODA</xref>) to follow the time course
defined by the differential equations until a steady state is
reached. If at 
<mml:math>
<mml:msup><mml:mn>10</mml:mn><mml:mn>10</mml:mn></mml:msup></mml:math>.
units of time no steady state has been reached the method halts with
no solution. If Use Newton is '1' an attempt to find the steady-state
via the damped Newton method is made at each intermediate time point.
A value of '1' (the default) indicates that COPASI shall use
integration.
</para>
</listitem>
</varlistentry>
<varlistentry><term>Use Back Integration</term>
<listitem>
<para>
This parameter is a boolean value to determine whether to use the ODE
solver (<xref linkend="LSODA">LSODA</xref>) to reverse the time course
(going backwards in time) defined by the differential equations until
a steady state is reached. If at 
<mml:math><mml:mn>-1</mml:mn><mml:mo>*</mml:mo>
<mml:msup><mml:mn>10</mml:mn><mml:mn>10</mml:mn></mml:msup></mml:math>.
units of time no steady state has been reached the method halts with
no solution. If Use Newton is '1' an attempt to find the steady-state
via the damped Newton method is made at each intermediate time point.
A value of '1' (the default) indicates that COPASI shall use
back integration.
</para>
</listitem>
</varlistentry>
<varlistentry><term>Accept Negative Concentrations</term>
<listitem>
<para>
This parameter is a boolean value to determine whether to accept a
steady-state, which contains negative concentrations. A value of '1'
indicates that negative concentrations are acceptable whereas a value
of '0' (the default) indicates that such states are discarded.
</para>
</listitem>
</varlistentry>
<varlistentry><term>Iteration Limit</term>
<listitem>
<para>
This parameter is a positive integer to determine the maximum number of
iterations the damped Newton method shall perform before it fails. The
default is '50'.
</para>
</listitem>
</varlistentry>
<varlistentry><term>Derivation Factor</term>
<listitem>
<para>
This is a numeric value to determine the step size used to calculate
<mml:math> 
 <mml:mi>f</mml:mi>
 <mml:mi>&apos;</mml:mi>
 <mml:mrow>
  <mml:mo>(</mml:mo>
  <mml:msub>
   <mml:mi>x</mml:mi>
   <mml:mrow>
    <mml:mi>i</mml:mi>
    <mml:mo>-</mml:mo>
    <mml:mn>1</mml:mn>
   </mml:mrow>
  </mml:msub>
  <mml:mo>)</mml:mo>
 </mml:mrow>
</mml:math>. The default is '0.001'.
</para>
</listitem>
</varlistentry>
<varlistentry><term>Resolution</term>
<listitem>
<para>
This is a positive numeric value to determine the resolution used to
decide whether the current state is acceptable as a steady-state. If
the absolute change of each state variable is smaller than the
resolutions the state is accepted. The default is <mml:math>
<mml:msup><mml:mn>10</mml:mn><mml:mn>-9</mml:mn></mml:msup></mml:math>.
Note that this value is interpreted as a concentration value, even though the calculation internally uses particle numbers. The reason for that is purely heuristical: In many cases the modeler will choose the units in a way that concentration values are neither extremely large not extremely small numerically so that the default value for this parameter leads to useful results. However generally it is not save to just keep the default value without checking. 
</para>
</listitem>
</varlistentry>
</variablelist>

</sect1>
<sect1 id="methodMCA" xreflabel="Metabolic Control Analysis">
<title>Metabolic Control Analysis</title>
<para>To be written.</para>

<variablelist><title>Options for MCA</title>
<varlistentry><term>Modulation Factor</term>
<listitem>
<para>
To be written
</para>
</listitem>
</varlistentry>
</variablelist>

<para>The rest of the options is described in the sections for <xref linkend="methodSteadyState">Steady State Analysis</xref> and <xref linkend="methodTimeCourse">Time Course Simulation</xref>.</para>

</sect1>


<sect1 id="optimizationMethod" xreflabel="Optimization Method">
<title>Optimization Methods</title>
<para>The optimization method as described in <xref
linkend="optimization">this chapter</xref> tries to minimize a given
objective function. There are several ways to do this and COPASI
supports many different methods for the minimization of an objective
function.</para>

<sect2 id="GeneticAlgorithm" xreflabel="Genetic Algorithm">
<title>Genetic Algorithm</title>

<para>
The genetic algorithm (GA)  
<citation>Baeck97</citation><citation>Baeck93</citation><citation>Michalewicz94</citation><citation>Mitchell95</citation>
 is a computational technique that mimics
evolution and is based on reproduction and selection. A GA is composed
of individuals that reproduce and compete, each one is a potential
solution to the (optimization) problem and is represented by a 
"genome" where each gene corresponds to one adjustable
parameter. At each generation of the GA, each individual is paired
with one other at random for reproduction. Two offspring are produced
by combining their genomes and allowing for "cross-over",
i.e., the two new individuals have genomes that are formed from a
combination of the genomes of their parents. Also each new gene might
have mutated, i.e. the parameter value might have changed slightly. At
the end of the generation, the algorithm has double the number of
individuals. Then each of the individuals is confronted with a number
of others to count how many does it outperform (the number of wins is
the number of these competitors that represent worse solutions than
itself). All the individuals are ranked by their number of wins, and
the population is again reduced to the original number of individuals
by eliminating those which have worse fitness (solutions). 
</para>
<para>
Many features of a GA may be varied. The details of this particular
implementation of the GA for optimization of biochemical kinetics are:

<itemizedlist mark='bullet'>
<listitem>
<para>
Parameters are encoded in genes using floating-point representation,
rather than the more usual binary representation. 
</para>
</listitem>

<listitem>
<para>
Mutation is carried out by adding to the gene a random number drawn
from a normal distribution with zero mean and a standard deviation of
10% of the parameter value. Whenever this makes the parameter (gene)
exceed one boundary, it is set to that boundary value.  
</para>
</listitem>

<listitem>
<para>
Cross-over is always performed at gene boundaries so that no gene is
ever disrupted. The number of cross-over points is a random number
between zero and half the number of adjustable parameters (uniform
distribution).
</para>
</listitem>

<listitem>
<para>
Selection is done by a tournament where each individual competes with
a number of others equal to 20% the population size. The competitors
are chosen at random.
</para>
</listitem>

<listitem>
<para>
The initial population contains one individual whose genes are the
initial parameter values, the genes of all other individuals are
initialized to a random value between their boundaries. If the
boundaries span two orders of magnitude or more, the random
distribution is exponential, otherwise normal.
</para>
</listitem>

<listitem>
<para>
Whenever the fittest individual has not changed for the last 10
generations, the 10% less fit individuals are replaced by individuals
with random genes. When the fittest individual has not changed for 30
generations, the worse 30% are substituted by individuals with random
genes. When the fittest individual has not changed for 50 generations,
the worse 50% are substituted by individuals with random genes. This
procedure helps the algorithm escape local minima and is somewhat
equivalent to increasing the mutation rate when the population has
become uniform.
</para>
</listitem>
</itemizedlist>

</para>
<variablelist><title>Options for Genetic Algorithm</title>
<varlistentry><term>Number of Generations</term>
<listitem>
<para>
The parameter is a positive integer value to determine the number of
generations the algorithm shall evolve the population. The default is
'200'. 
</para>
</listitem>
</varlistentry>
<varlistentry><term>Population Size</term>
<listitem>
<para>
The parameter is a positive integer value to determine the size of the
population, i.e., the number of individuals that survive after each
generation. The default is '20'.
</para>
</listitem>
</varlistentry>
<varlistentry><term>Random Number Generator</term>
<listitem>
<para>
The parameter is an enumeration value to determine which random number
generator this method shall use. COPASI provides two random number
generators R250 <citation>Maier91</citation>
 (selected through the value 0) and the
<ulink url="http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/emt.html">Mersenne
Twister </ulink><citation>Matsumoto98</citation>
 (selected through the value 1 (default)).
</para>
</listitem>
</varlistentry>
<varlistentry><term>Seed</term>
<listitem>
<para>
The parameter is a positive integer value to determine the seed for the
random number generator. A value of zero instructs COPASI to select a
"random" value.
</para>
</listitem>
</varlistentry>
</variablelist>
</sect2>

<sect2 id="GeneticAlgorithmSR" xreflabel="Genetic Algorithm SR">
<title>Genetic Algorithm SR</title>

<para>
The genetic algorithm with stochastic ranking is very similar to the
before described <xref linkend="GeneticAlgorithm" /> with tournament
selection. With two exception which are the mutations are not forced
to be within the boundaries and the selection is done through a bubble
sort with a random factor as described in
<citation>Runarsson00</citation>.
</para>

<itemizedlist mark='bullet'>
<listitem>
<para>
Parameters are encoded in genes using floating-point representation,
rather than the more usual binary representation. 
</para>
</listitem>

<listitem>
<para>
Mutation is carried out by adding to the gene a random number drawn
from a normal distribution with zero mean and a standard deviation of
10% of the parameter value. Parameters may exceed boundaries. Whenever
this happens or a constraint to the solution is violated the square of
the size of the violation is summed up, i.e., we calculate 
</para>
<para>
<mml:math>
 <mml:mrow>
  <mml:mo>&phi;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mrow>
   <mml:mrow>
    <mml:mrow>
     <mml:mrow>
      <mml:msub>
       <mml:mo>&sum;</mml:mo>
       <mml:mrow>
        <mml:msub>
         <mml:mi>p</mml:mi>
         <mml:mi>i</mml:mi>
        </mml:msub>
        <mml:mo>&lt;</mml:mo>
        <mml:msub>
         <mml:mi>l</mml:mi>
         <mml:msub>
          <mml:mi>p</mml:mi>
          <mml:mi>i</mml:mi>
         </mml:msub>
        </mml:msub>
       </mml:mrow>
      </mml:msub>
      <mml:msup>
       <mml:mrow>
        <mml:mo>(</mml:mo>
        <mml:mrow>
         <mml:msub>
          <mml:mi>l</mml:mi>
          <mml:msub>
           <mml:mi>p</mml:mi>
           <mml:mi>i</mml:mi>
          </mml:msub>
         </mml:msub>
         <mml:mo>-</mml:mo>
         <mml:msub>
          <mml:mi>p</mml:mi>
          <mml:mi>i</mml:mi>
         </mml:msub>
        </mml:mrow>
        <mml:mo>)</mml:mo>
       </mml:mrow>
       <mml:mn>2</mml:mn>
      </mml:msup>
     </mml:mrow>
     <mml:mo>+</mml:mo>
     <mml:mrow>
      <mml:msub>
       <mml:mo>&sum;</mml:mo>
       <mml:mrow>
        <mml:msub>
         <mml:mi>p</mml:mi>
         <mml:mi>i</mml:mi>
        </mml:msub>
        <mml:mo>&gt;</mml:mo>
        <mml:msub>
         <mml:mi>u</mml:mi>
         <mml:msub>
          <mml:mi>p</mml:mi>
          <mml:mi>i</mml:mi>
         </mml:msub>
        </mml:msub>
       </mml:mrow>
      </mml:msub>
      <mml:msup>
       <mml:mrow>
        <mml:mo>(</mml:mo>
        <mml:mrow>
         <mml:msub>
          <mml:mi>p</mml:mi>
          <mml:mi>i</mml:mi>
         </mml:msub>
         <mml:mo>-</mml:mo>
         <mml:msub>
          <mml:mi>u</mml:mi>
          <mml:msub>
           <mml:mi>p</mml:mi>
           <mml:mi>i</mml:mi>
          </mml:msub>
         </mml:msub>
        </mml:mrow>
        <mml:mo>)</mml:mo>
       </mml:mrow>
       <mml:mn>2</mml:mn>
      </mml:msup>
     </mml:mrow>
    </mml:mrow>
    <mml:mo>+</mml:mo>
    <mml:mrow>
     <mml:msub>
      <mml:mo>&sum;</mml:mo>
      <mml:mrow>
       <mml:msub>
        <mml:mi>c</mml:mi>
        <mml:mi>j</mml:mi>
       </mml:msub>
       <mml:mo>&lt;</mml:mo>
       <mml:msub>
        <mml:mi>l</mml:mi>
        <mml:msub>
         <mml:mi>c</mml:mi>
         <mml:mi>j</mml:mi>
        </mml:msub>
       </mml:msub>
      </mml:mrow>
     </mml:msub>
     <mml:msup>
      <mml:mrow>
       <mml:mo>(</mml:mo>
       <mml:mrow>
        <mml:msub>
         <mml:mi>l</mml:mi>
         <mml:msub>
          <mml:mi>c</mml:mi>
          <mml:mi>j</mml:mi>
         </mml:msub>
        </mml:msub>
        <mml:mo>-</mml:mo>
        <mml:msub>
         <mml:mi>c</mml:mi>
         <mml:mi>j</mml:mi>
        </mml:msub>
       </mml:mrow>
       <mml:mo>)</mml:mo>
      </mml:mrow>
      <mml:mn>2</mml:mn>
     </mml:msup>
    </mml:mrow>
   </mml:mrow>
   <mml:mo>+</mml:mo>
   <mml:mrow>
    <mml:msub>
     <mml:mo>&sum;</mml:mo>
     <mml:mrow>
      <mml:msub>
       <mml:mi>c</mml:mi>
       <mml:mi>j</mml:mi>
      </mml:msub>
      <mml:mo>&gt;</mml:mo>
      <mml:msub>
       <mml:mi>u</mml:mi>
       <mml:msub>
        <mml:mi>c</mml:mi>
        <mml:mi>j</mml:mi>
       </mml:msub>
      </mml:msub>
     </mml:mrow>
    </mml:msub>
    <mml:msup>
     <mml:mrow>
      <mml:mo>(</mml:mo>
      <mml:mrow>
       <mml:msub>
        <mml:mi>c</mml:mi>
        <mml:mi>j</mml:mi>
       </mml:msub>
       <mml:mo>-</mml:mo>
       <mml:msub>
        <mml:mi>u</mml:mi>
        <mml:msub>
         <mml:mi>c</mml:mi>
         <mml:mi>j</mml:mi>
        </mml:msub>
       </mml:msub>
      </mml:mrow>
      <mml:mo>)</mml:mo>
     </mml:mrow>
     <mml:mn>2</mml:mn>
    </mml:msup>
   </mml:mrow>
  </mml:mrow>
 </mml:mrow>
</mml:math>
</para>
<para>
where the parameters are given by 
<mml:math>
  <mml:mrow>
   <mml:msub>
    <mml:mi>p</mml:mi>
    <mml:mi>i</mml:mi>
   </mml:msub>
   <mml:mo>&in;</mml:mo>
   <mml:mrow>
    <mml:mo>(</mml:mo>
    <mml:mrow>
     <mml:msub>
      <mml:mi>l</mml:mi>
      <mml:msub>
       <mml:mi>p</mml:mi>
       <mml:mi>i</mml:mi>
      </mml:msub>
     </mml:msub>
     <mml:mi>,</mml:mi>
     <mml:mtext>&ThinSpace;</mml:mtext>
     <mml:msub>
      <mml:mi>u</mml:mi>
      <mml:msub>
       <mml:mi>p</mml:mi>
       <mml:mi>i</mml:mi>
      </mml:msub>
     </mml:msub>
    </mml:mrow>
    <mml:mo>)</mml:mo>
   </mml:mrow>
  </mml:mrow>
</mml:math> 
and the constraints by
<mml:math>
  <mml:mrow>
   <mml:msub>
    <mml:mi>c</mml:mi>
    <mml:mi>j</mml:mi>
   </mml:msub>
   <mml:mo>&in;</mml:mo>
   <mml:mrow>
    <mml:mo>(</mml:mo>
    <mml:mrow>
     <mml:msub>
      <mml:mi>l</mml:mi>
      <mml:msub>
       <mml:mi>c</mml:mi>
       <mml:mi>i</mml:mi>
      </mml:msub>
     </mml:msub>
     <mml:mi>,</mml:mi>
     <mml:mtext>&ThinSpace;</mml:mtext>
     <mml:msub>
      <mml:mi>u</mml:mi>
      <mml:msub>
       <mml:mi>c</mml:mi>
       <mml:mi>i</mml:mi>
      </mml:msub>
     </mml:msub>
    </mml:mrow>
    <mml:mo>)</mml:mo>
   </mml:mrow>
  </mml:mrow>
</mml:math>.
The value <mml:math><mml:mo>&phi;</mml:mo></mml:math> is used within
the selection.
</para>
</listitem>


<listitem>
<para>
Cross-over is always performed at gene boundaries so that no gene is
ever disrupted. The number of cross-over points is a random number
between zero and half the number of adjustable parameters (uniform
distribution).
</para>
</listitem>

<listitem>
<para>
Selection is done by the bubble sort described in
<citation>Runarsson00</citation>.
This sort incorporates a probability to compare
objective values for individuals with a 
<mml:math>
 <mml:mo>&phi;</mml:mo>
 <mml:mo>&ne;</mml:mo>
 <mml:mn>0</mml:mn>
</mml:math>. The pseudo code for the sort
is: <literallayout>  // Here sweepNum is optimal number of sweeps from paper, i.e., TotalPopulation
  for (i = 0; i &lt; sweepNum; i++)
    {
      wasSwapped = false;

      for (j = 0; j &lt; TotalPopulation - 1; j++)
        {
          // within bounds or random chance 
          if ((phi(j) == 0 and phi(j + 1) == 0) or UniformRandom(0, 1) &lt; Pf)
            {
              // compare objective function values
              if (Value(j) &gt; Value(j + 1))
                {
                  swap(j, j + 1);
                  wasSwapped = true;
                }
            }
          else // phi != 0 
            {
              // individual j further outside then j + 1
              if (phi(j) &gt; phi(j + 1))
                {
                  swap(j, j + 1);
                  wasSwapped = true;
                }
            }
        }

      // if no swap then break
      if (wasSwapped == false) break;
    }
</literallayout>
</para>
</listitem>

<listitem>
<para>
The initial population contains one individual whose genes are the
initial parameter values, the genes of all other individuals are
initialized to a random value between their boundaries. If the
boundaries span two orders of magnitude or more, the random
distribution is exponential, otherwise normal.
</para>
</listitem>

<listitem>
<para>
Whenever the fittest individual has not changed for the last 10
generations, the 10% less fit individuals are replaced by individuals
with random genes. When the fittest individual has not changed for 30
generations, the worse 30% are substituted by individuals with random
genes. When the fittest individual has not changed for 50 generations,
the worse 50% are substituted by individuals with random genes. This
procedure helps the algorithm escape local minima and is somewhat
equivalent to increasing the mutation rate when the population has
become uniform.
</para>
</listitem>
</itemizedlist>

<variablelist><title>Options for Genetic Algorithm SR</title>
<varlistentry><term>Number of Generations</term>
<listitem>
<para>
The parameter is a positive integer value to determine the number of
generations the algorithm shall evolve the population. The default is
'200'. 
</para>
</listitem>
</varlistentry>
<varlistentry><term>Population Size</term>
<listitem>
<para>
The parameter is a positive integer value to determine the size of the
population, i.e., the number of individuals that survive after each
generation. The default is '20'.
</para>
</listitem>
</varlistentry>
<varlistentry><term>Random Number Generator</term>
<listitem>
<para>
The parameter is an enumeration value to determine which random number
generator this method shall use. COPASI provides two random number
generators R250 <citation>Maier91</citation>
 (selected through the value 0) and the
<ulink url="http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/emt.html">Mersenne
Twister </ulink><citation>Matsumoto98</citation>
 (selected through the value 1 (default)).
</para>
</listitem>
</varlistentry>
<varlistentry><term>Seed</term>
<listitem>
<para>
The parameter is a positive integer value to determine the seed for the
random number generator. A value of zero instructs COPASI to select a
"random" value.
</para>
</listitem>
</varlistentry>
<varlistentry><term>Pf</term>
<listitem>
<para>
This parameter is a numerical value in the interval (0, 1) determining
the chance that individuals either outside the parameter boundaries or
violating the constraints are compared during the selection. The
default is '4.75'. 
</para>
</listitem>
</varlistentry>
</variablelist>
</sect2>

<sect2 id="HookeJeeves" xreflabel="Hooke &amp; Jeeves">
<title>Hooke &amp; Jeeves</title>

<para>
The method of Hooke and Jeeves
<citation>Bell66</citation><citation>Hooke61</citation><citation>Kaupe63</citation><citation>Swann72</citation>
is a direct search algorithm that
searches for the minimum of a nonlinear function without requiring (or
attempting to calculate) derivatives of the function. Instead it is
based on a heuristic that suggests a descent direction using the
values of the function calculated in a number of previous iterations. 
</para>

<variablelist><title>Options for Hooke &amp; Jeeves</title>
<varlistentry><term>Iteration Limit</term>
<listitem>
<para>
This parameter is positive integer determining the maximum number of
iterations the algorithm Sharl perform. The default is '50'.
</para>
</listitem>
</varlistentry>
<varlistentry><term>Tolerance</term>
<listitem>
<para>
This parameter is a positive value determining the tolerance with
which the solution shall be determined. If the improvement between two
steps is less than the tolerance the algorithm stops. The default is
'<mml:math>
 <mml:msup>
  <mml:mn>10</mml:mn>
  <mml:mn>-5</mml:mn>
 </mml:msup>
</mml:math>'. 
</para>
</listitem>
</varlistentry>
<varlistentry><term>Rho</term>
<listitem>
<para>
This parameter is a value in (0, 1) determining the factor with which
the steps size is reduced between iterations. The default is '0.2'.
</para>
</listitem>
</varlistentry>
</variablelist>
</sect2>

<sect2 id="LevenbergMarquardt" xreflabel="Levenberg - Marquardt">
<title>Levenberg - Marquardt</title>

<para>
Levenberg-Marquardt <citation>Levenberg44</citation><citation>Marquardt63</citation> is a gradient descent method. It is a hybrid
between the steepest descent and the Newton methods.
</para>

<para> 
The Newton optimization method searches for the minimum of a nonlinear
function by following descent directions determined from the
function's first and second partial derivatives. The steepest descent
method searches for a minimum based only on the first derivatives of
the function. While the Newton method converges quadratically towards
the minimum in its vicinity, it may not converge at all if it is far
away from it. On the other hand the steepest descent method only
converges linearly but is guaranteed to converge.
</para>

<para>
Levenberg first suggested an improvement to the Newton method in order
to make it more robust, i.e. to overcome the problem of
non-convergence. His suggestion was to add a factor to the diagonal
elements of the Hessian matrix of second derivatives when not close to
the minimum (this can be judged by how positive definite the matrix
is). The effect when this factor is large compared to the elements of
Hessian is that the method then becomes the steepest descent
method. Later Marquardt suggested that the factor should be
multiplicative rather than additive and also defined a heuristic to
make this factor increase or decrease. The method known as
Levenberg-Marquardt is thus an adaptive method that effectively
changes between the steepest descent to the Newton method.
</para>

<para>
The original suggestions of Levenberg and Marquardt were effective
to enhance the Gauss-Newton method, a variant of the Newton method
specifically for minimizing least-squares functions. In this case the
advantage is also that the second derivatives do not need to be
calculated as they are estimated from the gradient of the
residuals. Subsequently Goldfeld et
al. <citation>Goldfeld66</citation> extended the method to the
case of general non-linear functions.
</para>



<variablelist><title>Options for Levenberg - Marquardt</title>
<varlistentry><term>Iteration Limit</term>
<listitem>
<para>
This parameter is positive integer determining the maximum number of
iterations the algorithm shall perform. The default is '200'.
</para>
</listitem>
</varlistentry>
<varlistentry><term>Tolerance</term>
<listitem>
<para>
This parameter is a positive value determining the tolerance with
which the solution shall be determined. If the improvement between two
steps is less than the tolerance the algorithm stops. The default is
'<mml:math>
 <mml:msup>
  <mml:mn>10</mml:mn>
  <mml:mn>-5</mml:mn>
 </mml:msup>
</mml:math>'. 
</para>
</listitem>
</varlistentry>
</variablelist>
</sect2>

<sect2 id="EvolutionaryProgramming" xreflabel="Evolutionary Programming">
<title>Evolutionary Programming</title>

<para>
Evolutionary programming (EP)
<citation>Fogel92</citation><citation>Baeck93</citation><citation>Baeck97</citation>
is a computational technique that mimics evolution and is based on
reproduction and selection. An EP algorithm is composed of individuals
that reproduce and compete, each one is a potential solution to the
(optimization) problem and is represented by a "genome" where each
gene corresponds to one adjustable parameter. At each generation of
the EP, each individual reproduces asexually, i.e. divides into two
individuals. One of these contains exactly the same "genome" as the
parent while the other suffers some mutations (the parameter values of
each gene change slightly). At the end of the generation, the
algorithm has double the number of individuals. Then each of the
individuals is confronted with a number of others to count how many
does it outperform (the number of wins is the number of these
competitors that represent worse solutions than itself). All the
individuals are ranked by their number of wins, and the population is
again reduced to the original number of individuals by eliminating
those which have worse fitness (solutions).  
</para>

<variablelist><title>Options for Evolutionary Programming</title>
<varlistentry><term>Number of Generations</term>
<listitem>
<para>
The parameter is a positive integer value to determine the number of
generations the algorithm shall evolve the population. The default is
'200'. 
</para>
</listitem>
</varlistentry>
<varlistentry><term>Population Size</term>
<listitem>
<para>
The parameter is a positive integer value to determine the size of the
population, i.e., the number of individuals that survive after each
generation. The default is '20'.
</para>
</listitem>
</varlistentry>
<varlistentry><term>Random Number Generator</term>
<listitem>
<para>
The parameter is an enumeration value to determine which random number
generator this method shall use. COPASI provides two random number
generators R250 <citation>Maier91</citation>
 (selected through the value 0) and the
<ulink url="http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/emt.html">Mersenne
Twister </ulink><citation>Matsumoto98</citation>
 (selected through the value 1 (default)).
</para>
</listitem>
</varlistentry>
<varlistentry><term>Seed</term>
<listitem>
<para>
The parameter is a positive integer value to determine the seed for the
random number generator. A value of zero instructs COPASI to select a
"random" value.
</para>
</listitem>
</varlistentry>
</variablelist>
</sect2>

<sect2 id="RandomSearch" xreflabel="Random Search">
<title>Random Search</title>

<para>
Random search is an optimisation method that attempts to find the
optimum by testing the objective function's value on a series of
combinations of random values of the adjustable parameters. The random
vlues are generated complying with any boundaries selected by the
user, furthermore, any combinations of parameter values that do not
fulfill constraints on the variables are excluded. This means that the
method is capable of handling bounds on the adjustable parameters and
fulfilling constraints. 
</para>

<para>
For infinite number of iterations this method is garanteed to find the
global optimum of the objective function. In general one is interested
in processing a very large number of iterations. 
</para>

<variablelist><title>Options for Random Search</title>
<varlistentry><term>Number of Iterations</term>
<listitem>
<para>
This parameter is a positeve interger to determine the number of
parameter sets to be drawn before the algorithm stops. The default
value is '100000'.
</para>
</listitem>
</varlistentry>
<varlistentry><term>Random Number Generator</term>
<listitem>
<para>
The parameter is an enumeration value to determine which random number
generator this method shall use. COPASI provides two random number
generators R250 <citation>Maier91</citation>
 (selected through the value 0) and the
<ulink url="http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/emt.html">Mersenne
Twister </ulink><citation>Matsumoto98</citation>
 (selected through the value 1 (default)).
</para>
</listitem>
</varlistentry>
<varlistentry><term>Seed</term>
<listitem>
<para>
The parameter is a positive integer value to determine the seed for the
random number generator. A value of zero instructs COPASI to select a
"random" value.
</para>
</listitem>
</varlistentry>
</variablelist>
</sect2>

<sect2 id="EvolutionaryStrategySRES" xreflabel="Evolutionary Strategy (SRES)">
<title>Evolutionary Strategy (SRES)</title>

<para>
Evolutionary Strategies with Stochastic Ranking (SRES)
<citation>Runarsson00</citation> is similar to <xref
linkend="EvolutionaryProgramming"/>. However, a parent has multiple
offsprings during each generation. Each offspring will contain a
recombination of genes with another parent and additional
mutations. The algorithm assures that each parameter value will be
within its boundaries. But constraints to the solutions may be
violated. Whenever this happens the square of the size of the
violation is summed up, i.e., we calculate  
</para>
<para>
<mml:math>
 <mml:mrow>
  <mml:mo>&phi;</mml:mo>
  <mml:mo>=</mml:mo>
  <mml:mrow>
   <mml:mrow>
    <mml:mrow>
     <mml:msub>
      <mml:mo>&sum;</mml:mo>
      <mml:mrow>
       <mml:msub>
        <mml:mi>c</mml:mi>
        <mml:mi>j</mml:mi>
       </mml:msub>
       <mml:mo>&lt;</mml:mo>
       <mml:msub>
        <mml:mi>l</mml:mi>
        <mml:msub>
         <mml:mi>c</mml:mi>
         <mml:mi>j</mml:mi>
        </mml:msub>
       </mml:msub>
      </mml:mrow>
     </mml:msub>
     <mml:msup>
      <mml:mrow>
       <mml:mo>(</mml:mo>
       <mml:mrow>
        <mml:msub>
         <mml:mi>l</mml:mi>
         <mml:msub>
          <mml:mi>c</mml:mi>
          <mml:mi>j</mml:mi>
         </mml:msub>
        </mml:msub>
        <mml:mo>-</mml:mo>
        <mml:msub>
         <mml:mi>c</mml:mi>
         <mml:mi>j</mml:mi>
        </mml:msub>
       </mml:mrow>
       <mml:mo>)</mml:mo>
      </mml:mrow>
      <mml:mn>2</mml:mn>
     </mml:msup>
    </mml:mrow>
   </mml:mrow>
   <mml:mo>+</mml:mo>
   <mml:mrow>
    <mml:msub>
     <mml:mo>&sum;</mml:mo>
     <mml:mrow>
      <mml:msub>
       <mml:mi>c</mml:mi>
       <mml:mi>j</mml:mi>
      </mml:msub>
      <mml:mo>&gt;</mml:mo>
      <mml:msub>
       <mml:mi>u</mml:mi>
       <mml:msub>
        <mml:mi>c</mml:mi>
        <mml:mi>j</mml:mi>
       </mml:msub>
      </mml:msub>
     </mml:mrow>
    </mml:msub>
    <mml:msup>
     <mml:mrow>
      <mml:mo>(</mml:mo>
      <mml:mrow>
       <mml:msub>
        <mml:mi>c</mml:mi>
        <mml:mi>j</mml:mi>
       </mml:msub>
       <mml:mo>-</mml:mo>
       <mml:msub>
        <mml:mi>u</mml:mi>
        <mml:msub>
         <mml:mi>c</mml:mi>
         <mml:mi>j</mml:mi>
        </mml:msub>
       </mml:msub>
      </mml:mrow>
      <mml:mo>)</mml:mo>
     </mml:mrow>
     <mml:mn>2</mml:mn>
    </mml:msup>
   </mml:mrow>
  </mml:mrow>
 </mml:mrow>
</mml:math>
</para>
<para>
where the constraints are given by
<mml:math>
  <mml:mrow>
   <mml:msub>
    <mml:mi>c</mml:mi>
    <mml:mi>j</mml:mi>
   </mml:msub>
   <mml:mo>&in;</mml:mo>
   <mml:mrow>
    <mml:mo>(</mml:mo>
    <mml:mrow>
     <mml:msub>
      <mml:mi>l</mml:mi>
      <mml:msub>
       <mml:mi>c</mml:mi>
       <mml:mi>i</mml:mi>
      </mml:msub>
     </mml:msub>
     <mml:mi>,</mml:mi>
     <mml:mtext>&ThinSpace;</mml:mtext>
     <mml:msub>
      <mml:mi>u</mml:mi>
      <mml:msub>
       <mml:mi>c</mml:mi>
       <mml:mi>i</mml:mi>
      </mml:msub>
     </mml:msub>
    </mml:mrow>
    <mml:mo>)</mml:mo>
   </mml:mrow>
  </mml:mrow>
</mml:math>.
The value <mml:math><mml:mo>&phi;</mml:mo></mml:math> is used within
the selection. Which is done as described in <xref
linkend="GeneticAlgorithmSR"/> 
</para>

<variablelist><title>Options for Evolutionary Strategy (SRES)</title>
<varlistentry><term>Number of Generations</term>
<listitem>
<para>
The parameter is a positive integer value to determine the number of
generations the algorithm shall evolve the population. The default is
'200.' 
</para>
</listitem>
</varlistentry>
<varlistentry><term>Population Size</term>
<listitem>
<para>
The parameter is a positive integer value to determine the size of the
population, i.e., the number of individuals that survive after each
generation. The default is '20'.
</para>
</listitem>
</varlistentry>
<varlistentry><term>Random Number Generator</term>
<listitem>
<para>
The parameter is an enumeration value to determine which random number
generator this method shall use. COPASI provides two random number
generators R250 <citation>Maier91</citation>
 (selected through the value 0) and the
<ulink url="http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/emt.html">Mersenne
Twister </ulink><citation>Matsumoto98</citation>
 (selected through the value 1 (default)).
</para>
</listitem>
</varlistentry>
<varlistentry><term>Seed</term>
<listitem>
<para>
The parameter is a positive integer value to determine the seed for the
random number generator. A value of zero instructs COPASI to select a
"random" value.
</para>
</listitem>
</varlistentry>
<varlistentry><term>Pf</term>
<listitem>
<para>
This parameter is a numerical value in the interval (0, 1) determining
the chance that individuals either outside the parameter boundaries or
violating the constraints are compared during the selection. The
default is '4.75'. 
</para>
</listitem>
</varlistentry>
</variablelist>
</sect2>

<sect2 id="SteepestDescent" xreflabel="Steepest Descent">
<title>Steepest Descent</title>

<para>
Steepest descent <citation>Fogel92</citation> is an optimisation
method that follows the direction of steepest descent on the
hyper-surface of the objective function to find a local minimum. The
direction of steepest descent is defined by the negative of the
gradient of the objective function.
</para> 

<variablelist><title>Options for Steepest Descent</title>
<varlistentry><term>Iteration Limit</term>
<listitem>
<para>
This parameter is positive integer determining the maximum number of
iterations the algorithm shall perform. The default is '100'.
</para>
</listitem>
</varlistentry>
<varlistentry><term>Tolerance</term>
<listitem>
<para>
This parameter is a positive value determining the tolerance with
which the solution shall be determined. If the improvement between two
steps is less than the tolerance the algorithm stops. The default is
'<mml:math>
 <mml:msup>
  <mml:mn>10</mml:mn>
  <mml:mn>-6</mml:mn>
 </mml:msup>
</mml:math>'. 
</para>
</listitem>
</varlistentry>
</variablelist>
</sect2>
</sect1>


<sect1 id="lyapunovExponents" xreflabel="Lyapunov exponents">
  <title>Lyapunov exponents calculation</title>
  <para>
  </para> 
  <variablelist><title>Options for Lyapunov exponents calculation</title>
    <varlistentry><term>Orthonormalization interval</term>
      <listitem>
        <para>
        </para>
      </listitem>
    </varlistentry>
    <varlistentry><term>Overall time</term>
      <listitem>
        <para>
        </para>
      </listitem>
    </varlistentry>
  </variablelist>
  <para>
    The rest of the options is described in the section for <xref linkend="LSODA">LSODA deterministic simulation</xref>.
  </para>
</sect1>

</chapter>

